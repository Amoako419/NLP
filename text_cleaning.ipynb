{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: I love learning at CodeSignal; it's so interactive and fun!\n",
      "Cleaned: i love learning at codesignal its so interactive and fun\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert text to lower case\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation and special characters but leave spaces\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace to single spaces\n",
    "\n",
    "    return text.strip()  # Strip leading and trailing spaces\n",
    "\n",
    "test_texts = [\"I love learning at CodeSignal; it's so interactive and fun!\"]\n",
    "for text in test_texts:\n",
    "    print(f'Original: {text}')\n",
    "    print(f'Cleaned: {clean_text(text)}')\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.\n",
      "Cleaned: fill me in i enjoy problem solving tasks like these they are quite engaging\n",
      "--\n",
      "Original: Another ex:ample123 with special characters $#@!\n",
      "Cleaned: another ex ample with special characters\n",
      "--\n",
      "Original: example@mail.com is an email address.\n",
      "Cleaned: is an email address\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert text to lower case\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation and special characters\n",
    "    text = re.sub(r'\\d', ' ', text)  # Remove digits\n",
    "    text = re.sub(r'\\s\\s+', ' ', text)  # Remove extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "test_texts = ['Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.', \n",
    "              'Another ex:ample123 with special characters $#@!', \n",
    "              'example@mail.com is an email address.']\n",
    "for text in test_texts:\n",
    "    print(f'Original: {text}')\n",
    "    print(f'Cleaned: {clean_text(text)}')\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Sample Text with EMAIL! mailsample@mail.com\n",
      "Cleaned: sample text with email ail com\n",
      "--\n",
      "Original: URL example: https://www.codesignal.com\n",
      "Cleaned: url example\n",
      "--\n",
      "Original: Special characters #formed.\n",
      "Cleaned: special characters formed\n",
      "--\n",
      "Original: Digits included: 1234!!\n",
      "Cleaned: digits included\n",
      "--\n",
      "Original: Extra spaces   included.\n",
      "Cleaned: extra spaces included\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert text to lower case\n",
    "    text = re.sub(r'\\S*@\\S?', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation and special characters\n",
    "    text = re.sub(r'\\d', '', text)  # Remove digits\n",
    "    text = re.sub(r'\\s\\s+', ' ', text)  # Remove extra spaces\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "test_texts = ['Sample Text with EMAIL! mailsample@mail.com', \n",
    "              'URL example: https://www.codesignal.com', \n",
    "              'Special characters #formed.', \n",
    "              'Digits included: 1234!!',\n",
    "              'Extra spaces   included.']\n",
    "for text in test_texts:\n",
    "    print(f'Original: {text}')\n",
    "    print(f'Cleaned: {clean_text(text)}')\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  from where s my thing subject what car is this...\n",
      "1  from guy kuo subject si clock poll final call ...\n",
      "2  from thomas e willis subject pb questions orga...\n",
      "3  from joe green subject re weitek p organizatio...\n",
      "4  from jonathan mcdowell subject re shuttle laun...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert text to lower case\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation and special characters\n",
    "    text = re.sub(r'\\d', ' ', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace to single spaces\n",
    "\n",
    "    return text.strip()  # Strip leading and trailing spaces\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups_data = fetch_20newsgroups(subset='train')\n",
    "\n",
    "# Create DataFrame from the dataset\n",
    "# TODO: Write the required code to create a dataframe from the dataset. Name the dataframe as nlp_df and the column as 'text'.\n",
    "nlp_df = pd.DataFrame(newsgroups_data.data,columns=['text'])\n",
    "\n",
    "# Apply the clean_text function to the text data in the DataFrame\n",
    "# TODO: Write the code to apply the clean_text function to the 'text' column in the dataframe. \n",
    "nlp_df['text'] = nlp_df['text'].apply(lambda x:clean_text(x)) \n",
    "# Check the cleaned text\n",
    "print(nlp_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  from where s my thing subject what car is this...\n",
      "1  from guy kuo subject si clock poll final call ...\n",
      "2  from thomas e willis subject pb questions orga...\n",
      "3  from joe green subject re weitek p organizatio...\n",
      "4  from jonathan mcdowell subject re shuttle laun...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import re\n",
    "\n",
    "def lower_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_email(text):\n",
    "    return re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "\n",
    "def remove_url(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    return re.sub(r'\\W', ' ', text)\n",
    "\n",
    "def remove_digits(text):\n",
    "    return re.sub(r'\\d', ' ', text)\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def clean_text(text):\n",
    "  \"\"\"\n",
    "  This function cleans the text by applying all the cleaning steps in sequence.\n",
    "  \"\"\"\n",
    "  text = lower_text(text)\n",
    "  text = remove_email(text)\n",
    "  text = remove_url(text)\n",
    "  text = remove_special_chars(text)\n",
    "  text = remove_digits(text)\n",
    "  text = remove_extra_spaces(text)\n",
    "  return text  # Return the cleaned text\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups_data = fetch_20newsgroups(subset='train')\n",
    "\n",
    "# Create a DataFrame from the dataset\n",
    "nlp_df = pd.DataFrame(newsgroups_data.data,columns=['text'])\n",
    "\n",
    "# Apply the cleaning functions to the DataFrame\n",
    "nlp_df['text'] = nlp_df['text'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Check the cleaned text\n",
    "print(nlp_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
