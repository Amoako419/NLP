{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11f9ab6a80f4a7aa77a67d985dea065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001b4641c21648e2a74ee501a862a4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/481k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee82f3a564b499c8594a14cdb308085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5572 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: 4457 samples\n",
      "Test dataset: 1115 samples\n",
      "\n",
      "In Training Set:\n",
      "label\n",
      "ham     3859\n",
      "spam     598\n",
      "Name: count, dtype: int64\n",
      "\n",
      "In Testing Set:\n",
      "label\n",
      "ham     966\n",
      "spam    149\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify = Y)\n",
    "\n",
    "# Display the number of samples in training and test datasets\n",
    "print(f\"Training dataset: {len(X_train)} samples\")\n",
    "print(f\"Test dataset: {len(X_test)} samples\")\n",
    "\n",
    "# Print number of 'spam' and 'ham' in the training set\n",
    "print(\"\\nIn Training Set:\")\n",
    "print(Y_train.value_counts())\n",
    "\n",
    "# Print number of 'spam' and 'ham' in the testing set\n",
    "print(\"\\nIn Testing Set:\")\n",
    "print(Y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 13.42% spam and 86.58% ham messages.\n",
      "Test set has 13.36% spam and 86.64% ham messages.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "\n",
    "# spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "# spam_dataset = pd.DataFrame(spam_dataset)  # Load the txt data as dataframe\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset['message']  \n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y) \n",
    "\n",
    "# Calculate and display the percentage of spam vs ham messages in the training set\n",
    "spam_ratio_train = round((Y_train.value_counts()['spam'] / Y_train.value_counts().sum()) * 100, 2)\n",
    "ham_ratio_train = round((Y_train.value_counts()['ham'] / Y_train.value_counts().sum()) * 100, 2)\n",
    "\n",
    "print(f\"Training set has {spam_ratio_train}% spam and {ham_ratio_train}% ham messages.\")\n",
    "\n",
    "# Calculate and display the percentage of spam vs ham messages in the test set\n",
    "spam_ratio_test = round((Y_test.value_counts()['spam'] / Y_test.value_counts().sum()) * 100, 2)\n",
    "ham_ratio_test = round((Y_test.value_counts()['ham'] / Y_test.value_counts().sum()) * 100, 2)\n",
    "\n",
    "print(f\"Test set has {spam_ratio_test}% spam and {ham_ratio_test}% ham messages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 5572 rows and 2 columns.\n",
      "\n",
      "The unique values for classification labels and their count are:\n",
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n",
      "\n",
      "The first 'ham' message is:\n",
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "The first 'spam' message is:\n",
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# The dataset is loaded directly using the 'datasets' library\n",
    "import datasets\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)  # Load the txt data as dataframe\n",
    "\n",
    "# Print number of rows and columns in the dataset\n",
    "print(f\"The dataset has {spam_dataset.shape[0]} rows and {spam_dataset.shape[1]} columns.\")\n",
    "\n",
    "# Print unique value counts of classification labels\n",
    "print(\"\\nThe unique values for classification labels and their count are:\")\n",
    "print(spam_dataset['label'].value_counts())\n",
    "\n",
    "# Print the first 'ham' message and the first 'spam' message in the dataset\n",
    "print(\"\\nThe first 'ham' message is:\")\n",
    "print(spam_dataset[spam_dataset['label'] == 'ham'].iloc[0]['message'])\n",
    "\n",
    "print(\"\\nThe first 'spam' message is:\")\n",
    "print(spam_dataset[spam_dataset['label'] == 'spam'].iloc[0]['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solution(n):\n",
    "    return n // 10 + n % 10\n",
    "\n",
    "solution(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 20%10\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier with alpha=0: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split using stratified cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data \n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the MultinomialNB model with alpha=0\n",
    "naive_bayes_model = MultinomialNB(alpha=1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "naive_bayes_model.fit(X_train_count, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = naive_bayes_model.predict(X_test_count)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = metrics.accuracy_score(Y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy of Naive Bayes Classifier with alpha=0: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "spam_dataset = datasets.load_dataset('codesignal/sms-spam-collection', split='train')\n",
    "spam_dataset = pd.DataFrame(spam_dataset)\n",
    "\n",
    "# Define X (input features) and Y (output labels)\n",
    "X = spam_dataset[\"message\"]\n",
    "Y = spam_dataset[\"label\"]\n",
    "\n",
    "# Perform the train test split using stratified cross-validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data \n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the MultinomialNB model\n",
    "naive_bayes_model = MultinomialNB(alpha=1) \n",
    "\n",
    "# Fit the model on the training data\n",
    "naive_bayes_model.fit(X_train_count, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = naive_bayes_model.predict(X_test_count)\n",
    "\n",
    "print(f\"The model's first 10 predictions: {y_pred[:10]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
